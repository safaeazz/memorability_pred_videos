{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704cdd90",
   "metadata": {},
   "source": [
    "### Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9737100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os,glob\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns \n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import torch,random\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import IterableDataset, DataLoader, TensorDataset, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from scipy import interpolate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 42\n",
    "##### setting deterministic setting for torch\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2578c6",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f96682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g-t files\n",
    "path1 = './training_set/'\n",
    "path2 = './development_set/'\n",
    "\n",
    "file1 = 'train_scores.csv'\n",
    "file2 = 'dev_scores.csv'\n",
    "\n",
    "features_path1 = 'C3D/'\n",
    "features_path2 = './Features/efficientnet_b3/'\n",
    "features_path3 = './Features/densenet121/'\n",
    "\n",
    "# get data\n",
    "df1 = pd.read_csv(path1+file1,sep=',')\n",
    "df2 = pd.read_csv(path2+file2,sep=',')\n",
    "\n",
    "data1 = df1[[\"video_id\",\"scores_short_term\",\"decay_alpha\"]]\n",
    "data2 = df2[[\"video_id\",\"scores_short_term\",\"decay_alpha\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a71e4a",
   "metadata": {},
   "source": [
    "### Read C3D features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4f1f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read C3D features\n",
    "def read_csv_feat(file):\n",
    "    df = pd.read_csv(file,sep=',')\n",
    "    feat = df.columns.values\n",
    "    #feat = [f1.strip(\" \") for f1 in feat]\n",
    "    feat = [float('0.'+f1.split(\".\")[-1]) if len(f1.split(\".\"))>2 else float(f1) for f1 in feat]\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795e287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data processed:  (7000, 4096) (7000, 1)\n",
      "[INFO] 3110.6872770786285\n",
      "val data processed:  (1500, 4096) (1500, 1)\n",
      "[INFO] 610.2185342311859\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test = [],[]\n",
    "y_train,y_test = [],[]\n",
    "\n",
    "lst = os.listdir(path1+features_path1)\n",
    "lst2 = os.listdir(path2+features_path1)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(len(lst)):\n",
    "    f = lst[i]\n",
    "    label = data1.loc[data1['video_id'] == int(f.split('.')[0])]['scores_short_term']\n",
    "    feat = read_csv_feat(path1+features_path1+f)\n",
    "    X_train.append(feat)\n",
    "    y_train.append(label)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print('training data processed: ',X_train.shape,y_train.shape)\n",
    "print('[INFO]',time.time() - start)\n",
    "start = time.time()\n",
    "\n",
    "for i in range(len(lst2)):\n",
    "    f = lst2[i]\n",
    "    label = data2.loc[data2['video_id'] == int(f.split('.')[0])]['scores_short_term']\n",
    "    feat = read_csv_feat(path2+features_path1+f)\n",
    "    X_test.append(feat)\n",
    "    y_test.append(label)\n",
    "\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print('val data processed: ',X_test.shape, y_test.shape)\n",
    "print('[INFO]',time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421564b",
   "metadata": {},
   "source": [
    "### Read Resnet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bdd608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "X_train = []\n",
    "y_train = []\n",
    "lst = sorted(os.listdir(path1+features_path1))\n",
    "\n",
    "start = time.time()\n",
    "for f1, f2, f3 in zip(*[iter(lst)]*3):\n",
    "    label = data1.loc[data1['video_id'] == int(f1.split('-')[0])]['scores_short_term'].values\n",
    "    feat = [np.load(path1+features_path1+f1),np.load(path1+features_path1+f2),np.load(path1+features_path1+f3)]\n",
    "    X_train.append(np.array(feat).squeeze())\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print('data processed: ',X_train.shape,y_train.shape)\n",
    "print('[INFO]',time.time() - start)\n",
    "\n",
    "## validation data\n",
    "X_test = []\n",
    "y_test = []\n",
    "lst2 = sorted(os.listdir(path2+features_path1))\n",
    "\n",
    "start = time.time()\n",
    "for f1, f2, f3 in zip(*[iter(lst2)]*3):\n",
    "    label = data2.loc[data2['video_id'] == int(f1.split('-')[0])]['scores_short_term'].values\n",
    "    feat = [np.load(path2+features_path1+f1),np.load(path2+features_path1+f2),np.load(path2+features_path1+f3)]\n",
    "    X_test.append(np.array(feat).squeeze())\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "print('data processed: ',X_test.shape,y_test.shape)\n",
    "print('[INFO]',time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17794200",
   "metadata": {},
   "source": [
    "### Quick test ==> C3D features with SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab61d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = SVR(kernel='rbf',C=100,gamma=1e-3)\n",
    "#regr = MultiOutputRegressor(model)\n",
    "SVM_reg = regr.fit(X_train,y_train)\n",
    "svm_preds = SVM_reg.predict(X_test)\n",
    "\n",
    "# performance\n",
    "print('-------------------')\n",
    "print('|Model performance|')\n",
    "print('-------------------')\n",
    "\n",
    "corr1 = float(spearmanr(svm_preds,y_test)[0])\n",
    "corr2 = float(pearsonr(svm_preds,y_test)[0])\n",
    "mse = mean_squared_error(svm_preds,y_test)\n",
    "r_square = r2_score(svm_preds,y_test)\n",
    "res = explained_variance_score(svm_preds,y_test)\n",
    "\n",
    "\n",
    "print(f\"MSE: {round(mse,4)}\")\n",
    "print(f\"R_square: {round(r_square,4)}\")\n",
    "print(f\"score: {round(res,4)}\")\n",
    "\n",
    "print(f\"Spearman corr: {round(corr1,4)}\")\n",
    "print(f\"Pearson corr: {round(corr2,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b39bc",
   "metadata": {},
   "source": [
    "### Divide labels into high and low scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "th1,th2 = 0.7,0.9\n",
    "th = .8\n",
    "idx11 = np.argwhere(y_train>=th)[:,0]\n",
    "idx22 = np.argwhere(y_train<th)[:,0]\n",
    "idx33,_ = np.where((y_train>th1) & (y_train<th2))\n",
    "\n",
    "y_train11 = np.array([y_train[i] if i in idx11 else 0 for i in range(len(y_train))])\n",
    "y_train22 = np.array([y_train[i] if i in idx22 else 0 for i in range(len(y_train))])\n",
    "\n",
    "y_train1,y_train2= np.expand_dims(y_train11,axis=1),np.expand_dims(y_train22,axis=1)\n",
    "labels = np.concatenate((y_train1,y_train2),axis=1).astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6000edfa",
   "metadata": {},
   "source": [
    "### Training with Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8385d",
   "metadata": {},
   "source": [
    "### 1. Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ff406dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class non_LinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(non_LinearNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4096, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(1024,512)\n",
    "        self.fc4 = nn.Linear(512,128)\n",
    "        self.fc5 = nn.Linear(512,2)\n",
    "\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.act =  nn.Sigmoid()\n",
    "        self.drop = nn.Dropout(p=0.0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bn = nn.BatchNorm1d(2)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.bn3 = nn.BatchNorm1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        #x = self.act(self.fc3(x))\n",
    "        #x = self.act(self.fc4(x))\n",
    "        out = self.fc5(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125731c",
   "metadata": {},
   "source": [
    "### 2. CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7c07875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convNet(nn.Module):\n",
    "     def __init__(self): \n",
    "        super(convNet,self).__init__()\n",
    "        self.layer1 = nn.Conv1d(in_channels=1, out_channels=8, kernel_size=1) \n",
    "        self.act1 = nn.Sigmoid()\n",
    "        self.act2 = nn.AdaptiveMaxPool1d(output_size=1024) \n",
    "        \n",
    "        self.layer2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=1) \n",
    "        self.act3 = nn.Tanh() \n",
    "        self.act4 = nn.AdaptiveMaxPool1d(output_size=512)\n",
    "        \n",
    "        self.layer3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1) \n",
    "        self.act5 = nn.Tanh() \n",
    "        self.act6 = nn.AdaptiveMaxPool1d(output_size=128)\n",
    "        \n",
    "        self.layer4 = nn.Conv1d(in_channels=64, out_channels=1, kernel_size=1) \n",
    "        self.act7 = nn.Tanh() \n",
    "        self.act8 = nn.AdaptiveMaxPool1d(output_size=64)\n",
    "        self.linear_layer = nn.Linear(in_features=64, out_features=2)\n",
    "    \n",
    "     def forward(self, x): \n",
    "            \n",
    "        x = self.act3(self.act2(self.layer1(x))) \n",
    "        x = self.act3(self.act4(self.layer2(x))) \n",
    "        x = self.act3(self.act6(self.layer3(x))) \n",
    "        x = self.act3(self.act8(self.layer4(x))) \n",
    "        x = x.reshape(x.shape[0], -1) \n",
    "        out = self.linear_layer(x) \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a19df9",
   "metadata": {},
   "source": [
    "### 3. Vision Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "39b7ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from vit_pytorch import ViT\n",
    "\n",
    "IM1 = X_train.reshape(X_train.shape[0],64,64)\n",
    "IM2 = X_test.reshape(X_test.shape[0],64,64)\n",
    "\n",
    "imgs = np.array([cv2.merge((imgray,imgray,imgray)) for imgray in IM1])\n",
    "imgs_te = np.array([cv2.merge((imgray,imgray,imgray)) for imgray in IM2])\n",
    "\n",
    "\n",
    "vit_model = ViT(\n",
    "    image_size = 64,\n",
    "    patch_size = 8,\n",
    "    num_classes = 2,\n",
    "    dim = 16,\n",
    "    depth = 8,\n",
    "    heads = 8,\n",
    "    mlp_dim = 512,\n",
    "    dropout = 0.0,\n",
    "    emb_dropout = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d8d3c",
   "metadata": {},
   "source": [
    "### 4. LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e32900",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, hidden_size2,num_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden = None\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size2)\n",
    "        self.fc2 = nn.Linear(hidden_size2, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "     \n",
    "        #out, self.hidden = self.lstm(x, self.hidden)  \n",
    "        out, (final_hidden_state, final_cell_state) = self.lstm(x, self.hidden)  \n",
    "        #out = out.reshape(-1, self.hidden_size)       \n",
    "        #out = self.fc(out)  \n",
    "        out = self.sig(self.fc1(final_hidden_state[-1]))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24227c2",
   "metadata": {},
   "source": [
    "### init parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6bba25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize = 64\n",
    "lr = 0.0001\n",
    "epochs = 50\n",
    "\n",
    "tr_dataset = TensorDataset(torch.tensor(imgs),torch.tensor(labels)) # use y_train instead of labels for one label\n",
    "valid_dataset = TensorDataset(torch.tensor(imgs_te),torch.tensor(y_test)) \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=tr_dataset,batch_size=bsize,shuffle=True,num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,batch_size=bsize,shuffle=True,num_workers=0)\n",
    "\n",
    "#model = convNet()\n",
    "#model = non_LinearNet()\n",
    "#model = vit_model()\n",
    "\n",
    "model = LSTM_model(2048, 512,128, 3, 2)\n",
    "params = list(model.parameters())\n",
    "\n",
    "optimizer = optim.Adam(params, lr=lr)    \n",
    "#scheduler = MultiStepLR(optimizer, milestones=[100,200], gamma=0.5)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c62c8",
   "metadata": {},
   "source": [
    "### start training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0854c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "tr_loss = []\n",
    "te_loss = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):  \n",
    "    train_loss, test_loss, pcc = 0.0, 0.0, 0.0,\n",
    "        for data1 in train_loader:\n",
    "\n",
    "        inputs1,labels1,y = data1\n",
    "        # if model != lstm\n",
    "        #inputs1 = inputs1.unsqueeze(1).float()\n",
    "        labels1 = labels1.squeeze().float()\n",
    "        y = y.squeeze().float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #if model == vision transformer\n",
    "        #outputs1= v(inputs1.permute(0,3,1,2).float())\n",
    "        outputs1  = outputs1.squeeze()\n",
    "        loss1 = criterion(outputs1, labels1)#+ criterion(torch.sum(outputs1,1),y)\n",
    "        train_loss += loss1.item()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    #scheduler.step()\n",
    "\n",
    "    print('[INFO]: start testing')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data2 in tqdm(valid_loader):        \n",
    "            inputs2, labels2 = data2\n",
    "            #inputs2 =  inputs2.unsqueeze(1).float()\n",
    "            labels2 = labels2.float().squeeze()\n",
    "            #if model == visiom transformer \n",
    "            #outputs2 = v(inputs2.permute(0,3,1,2).float())\n",
    "            #else\n",
    "            outputs2 = model(inputs2)\n",
    "            outputs2 = outputs2.squeeze()\n",
    "            # sum labels\n",
    "            outputs2 = torch.sum(outputs2,1)\n",
    "\n",
    "            loss2 = criterion(outputs2, labels2)\n",
    "            test_loss += loss2.item()\n",
    "\n",
    "            corr = spearmanr(outputs2.cpu().detach(),labels2.cpu().detach())[0]\n",
    "            pcc += np.arctanh(corr1)\n",
    " \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    test_loss = test_loss/len(valid_loader)\n",
    "    pcc = pcc/len(valid_loader)\n",
    "    tr_loss.append(train_loss)\n",
    "    te_loss.append(test_loss)\n",
    "\n",
    "\n",
    "\n",
    "    print('epoch ',epoch, 'training loss ', train_loss, 'testing loss ', test_loss)\n",
    "    print('epoch ',epoch, 'testing correlation ', pcc1)\n",
    "\n",
    "print('Finished Training/Testing...')\n",
    "print('[INFO] ellapsed time: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111ff47",
   "metadata": {},
   "source": [
    "### Results: Model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model predictions\n",
    "out = model(torch.tensor(X_test).unsqueeze(1).float())\n",
    "#out = model(torch.tensor(imgs_te).permute(0,3,1,2).float()) #if using vision transformer\n",
    "out_all = out.squeeze().detach().numpy()\n",
    "\n",
    "\n",
    "# model performance\n",
    "corr1 = float(spearmanr(pred,y_test1)[0])\n",
    "corr2 = float(pearsonr(pred,y_test1)[0])\n",
    "mse = mean_squared_error(pred,y_test1)\n",
    "mae = mean_absolute_error(pred,y_test1)\n",
    "r_square = r2_score(y_test1, pred)\n",
    "res = explained_variance_score(y_test1,pred)\n",
    "\n",
    "# print output\n",
    "print('------------------')\n",
    "print(\"|Model performance |\")\n",
    "print('--------------------')\n",
    "print(f\"MSE: {round(mse,4)}\")\n",
    "print('-------------------')\n",
    "print(f\"MAE: {round(mae,4)}\")\n",
    "print('--------------------')\n",
    "print(f\"res: {round(res,4)}\")\n",
    "print('------------------------------')\n",
    "print(f\"R_square: {round(r_square,4)}\")\n",
    "print('--------------------------------')\n",
    "print(f\"Spearman corr: {round(corr1,4)}\")\n",
    "print('-------------------------------')\n",
    "print(f\"Pearson corr: {round(corr2,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fe29c2",
   "metadata": {},
   "source": [
    "### Results: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f9af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# loss and correlation variations over epochs\n",
    "#############################################\n",
    "\n",
    "print('-------------------------------------------')\n",
    "print(\"loss and correlation variations over epochs\")\n",
    "print('-------------------------------------------')\n",
    "\n",
    "idx = random.sample(range(1, len(pred)), 20)\n",
    "plt.plot(tr_loss,color='r',label='train_loss')\n",
    "plt.plot(te_loss,color='b',label ='valid_loss')\n",
    "plt.legend()\n",
    "plt.gca().set_title('loss variations over epochs')\n",
    "\n",
    "plt.show()\n",
    "############################\n",
    "# true vs. predictions plots\n",
    "############################\n",
    "\n",
    "print('--------------------------')\n",
    "print(\"true vs. predictions plots\")\n",
    "print('--------------------------')\n",
    "\n",
    "plt.plot(y_test1[idx],color='r',label ='true labels')\n",
    "plt.plot(pred[idx],color='b',label ='prediction')\n",
    "plt.legend()\n",
    "plt.gca().set_title('true scores vs. predicted scores')\n",
    "plt.show()\n",
    "\n",
    "##################################\n",
    "# Features and labels distribution\n",
    "##################################\n",
    "\n",
    "''' \n",
    "print('---------------------------------------------')\n",
    "print(\"Features and labels distribution by threshold\")\n",
    "print('---------------------------------------------')\n",
    "\n",
    "th = 0.6\n",
    "\n",
    "random_feat = random_x        \n",
    "idx1 = np.argwhere(y_test1>th)\n",
    "idx2 = np.argwhere(y_test1<=th)\n",
    "\n",
    "feat1 = feat[idx1,:].squeeze(1)\n",
    "feat2 = feat[idx2,:].squeeze(1)\n",
    "\n",
    "yt1 = y_test1[idx1]\n",
    "yt2 = y_test1[idx2]\n",
    "\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(feat1,label='> th')\n",
    "sns.distplot(feat2,label='< th')\n",
    "plt.gca().set_title('features distribution')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(yt1)\n",
    "plt.gca().set_title('labels distribution (score>str(th))')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(yt2)\n",
    "plt.gca().set_title('labels distribution (scorestr(th))')\n",
    "\n",
    "plt.show()\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
